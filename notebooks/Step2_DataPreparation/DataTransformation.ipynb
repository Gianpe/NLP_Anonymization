{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DataTransformation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOC3YHvM6Y7TS0leJIR7cl7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Transform annotated json files"],"metadata":{"id":"W9HEHSYfYayH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"I-5dNttIXYkq"},"outputs":[],"source":["data_annotated = pd.read_json(data_path +'/manually_annotated_dataset.json')"]},{"cell_type":"code","source":["import re\n","def pad(text):\n","    text = re.sub(\"([.,!?(')])\", r' \\1 ', text)\n","    text = re.sub('\\s{2,}', ' ', text)\n","    return text"],"metadata":{"id":"OPD4gu2JQHJE","executionInfo":{"status":"ok","timestamp":1642015580232,"user_tz":-60,"elapsed":7,"user":{"displayName":"GIANMARCO PEPI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04653772218915222099"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["def get_tokens(text):\n","    tokens = pad(text).split(' ')\n","    return tokens"],"metadata":{"id":"FG2yER_yKoQV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def nearest_entities(text, e1, e2):\n","    occ1 = [i for i in range(len(text)) if text.startswith(e1 , i)]\n","    occ2 = [i for i in range(len(text)) if text.startswith(e2, i)]\n","    \n","    minimum = len(text)\n","    indexes = (0,0)\n","\n","    for i1,v1 in enumerate(occ1):\n","        for i2,v2 in enumerate(occ2):\n","            if abs(v1-v2) < minimum:\n","                minimum = abs(v1-v2)\n","                \n","                indexes = (i1,i2)\n","    tok_list = get_tokens(text)\n","    occ1_tokens = []\n","    for i,x in enumerate(tok_list):\n","        if len(get_tokens(e1)) == 1:\n","            if x == get_tokens(e1)[0]:\n","                occ1_tokens.append(i)\n","        elif len(get_tokens(e1)) == 2:\n","            if x == get_tokens(e1)[0] and tok_list[i+1] == get_tokens(e1)[1]:\n","                occ1_tokens.append(i)\n","        else:\n","            if x == get_tokens(e1)[0] and tok_list[i+1] == get_tokens(e1)[1] and tok_list[i+2] == get_tokens(e1)[2]:\n","                occ1_tokens.append(i)\n","    occ2_tokens = []\n","    for i,x in enumerate(tok_list):\n","        if len(get_tokens(e2)) == 1:\n","            if x == get_tokens(e2)[0]:\n","                occ2_tokens.append(i)\n","        elif len(get_tokens(e2)) == 2:\n","            if x == get_tokens(e2)[0] and tok_list[i+1] == get_tokens(e2)[1]:\n","                occ2_tokens.append(i)\n","        else:\n","            if x == get_tokens(e2)[0] and tok_list[i+1] == get_tokens(e2)[1] and tok_list[i+2] == get_tokens(e2)[2]:\n","                occ2_tokens.append(i)\n","    return occ1[indexes[0]], occ2[indexes[1]], occ1_tokens[indexes[0]], occ2_tokens[indexes[1]]"],"metadata":{"id":"XmUBnySx7Nqb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_dict(df_row):\n","    tokens_list = get_tokens(df_row['SentText'])\n","    text = df_row['SentText']\n","    diz = {\"document\" : text,\n","           \"tokens\": [],\n","           \"relations\" : []}\n","    entities_list = []\n","    for rel in df_row['RelationMentions']:\n","        entity_1 = rel['Arg1Text']\n","        entity_2 = rel['Arg2Text']\n","        if entity_1 not in text or entity_2 not in text:\n","            continue\n","         \n","        tupla = nearest_entities(text, entity_1, entity_2)\n","        #print(tupla)\n","\n","\n","        if entity_1 not in df_row['EntityMentions']:\n","            continue\n","        ent1_diz = {\"text\": entity_1,\n","                                \"start\": tupla[0],\n","                                \"end\": tupla[0] + len(entity_1),\n","                                \"token_start\": tupla[2],\n","                                \"token_end\": tupla[2] + len(get_tokens(entity_1)) -1,\n","                                \"entityLabel\": rel['RelationNames'][0].split('/')[2].upper()}\n","        \n","        \n","\n","        ent2_diz = {\"text\": entity_2,\n","                                \"start\": tupla[1],\n","                                \"end\": tupla[1] + len(entity_2),\n","                                \"token_start\": tupla[3],\n","                                \"token_end\": tupla[3] + len(get_tokens(entity_2)) -1,\n","                                \"entityLabel\": 'IMPUTATO'}\n","        diz['relations'].append({ \"child\": ent2_diz[\"token_start\"], \"head\": ent1_diz[\"token_start\"], \"relationLabel\": rel['RelationNames'][0].split('/')[1].upper() })\n","        if ent2_diz not in diz['tokens']:\n","            diz['tokens'].append(ent2_diz)\n","        if ent1_diz not in diz['tokens']:\n","\n","            diz['tokens'].append(ent1_diz)\n","            \n","            \n","\n","        \n","        \n","        \n","    return diz"],"metadata":{"id":"UGCCBxS7-FRb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(data_annotated.shape[0]):\n","    try:\n","        create_dict(data_annotated.iloc[i])\n","    except:\n","        print(i)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBqV1lM-GLjD","executionInfo":{"status":"ok","timestamp":1641752943946,"user_tz":-60,"elapsed":857,"user":{"displayName":"GIANMARCO PEPI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04653772218915222099"}},"outputId":"746aa9e8-1e71-4d8e-a38c-96d09d70b6cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","15\n"]}]},{"cell_type":"code","source":["data_annotated = data_annotated.drop([0,15])\n","data_annotated"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"X7AVKXViGvKU","executionInfo":{"status":"ok","timestamp":1641753086908,"user_tz":-60,"elapsed":297,"user":{"displayName":"GIANMARCO PEPI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04653772218915222099"}},"outputId":"f6c5762d-81ad-4880-d295-31194da8030d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-cc628fe5-d191-4b0e-8e4e-d3a20881293a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>SentText</th>\n","      <th>EntityMentions</th>\n","      <th>RelationMentions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>la corte di appello di campobasso confermava ...</td>\n","      <td>[corte di appello, iuliano nadia]</td>\n","      <td>[{'Arg1Text': 'corte di appello', 'Arg2Text': ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11 tribunale di pavia, con sentenza 4 , su ri...</td>\n","      <td>[tribunale, borsan maricel, socio marius]</td>\n","      <td>[{'Arg1Text': 'tribunale', 'Arg2Text': 'borsan...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>la corte di appello di firenze ha confermato ...</td>\n","      <td>[corte di appello, giuseppe patruno]</td>\n","      <td>[{'Arg1Text': 'corte di appello', 'Arg2Text': ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>il tribunale di milano, in riforma della sent...</td>\n","      <td>[tribunale, herrera jara luis]</td>\n","      <td>[{'Arg1Text': 'tribunale', 'Arg2Text': 'herrer...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>la corte di appello di perugia, in parziale r...</td>\n","      <td>[corte di appello, hudorovich simonetta]</td>\n","      <td>[{'Arg1Text': 'corte di appello', 'Arg2Text': ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>166</th>\n","      <td>con la sentenza impugnata la corte di appello...</td>\n","      <td>[corte di appello, albert mecja]</td>\n","      <td>[{'Arg1Text': 'corte di appello', 'Arg2Text': ...</td>\n","    </tr>\n","    <tr>\n","      <th>167</th>\n","      <td>la corte di appello di ancona, con la sentenz...</td>\n","      <td>[tribunale, villani greta]</td>\n","      <td>[{'Arg1Text': 'tribunale', 'Arg2Text': 'villan...</td>\n","    </tr>\n","    <tr>\n","      <th>168</th>\n","      <td>francesco mastrogiaconno, attraverso il propr...</td>\n","      <td>[francesco mastrogiaconno, difensore]</td>\n","      <td>[{'Arg1Text': 'difensore', 'Arg2Text': 'france...</td>\n","    </tr>\n","    <tr>\n","      <th>169</th>\n","      <td>con l ordinanza indicata in epigrafe, emessa ...</td>\n","      <td>[tribunale, castagnini renato]</td>\n","      <td>[{'Arg1Text': 'tribunale', 'Arg2Text': 'castag...</td>\n","    </tr>\n","    <tr>\n","      <th>170</th>\n","      <td>con ordinanza in data 23/07/2021- dep. 4/08/2...</td>\n","      <td>[tribunale, kumbulla jetmir]</td>\n","      <td>[{'Arg1Text': 'tribunale', 'Arg2Text': 'kumbul...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>169 rows Ã— 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc628fe5-d191-4b0e-8e4e-d3a20881293a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cc628fe5-d191-4b0e-8e4e-d3a20881293a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cc628fe5-d191-4b0e-8e4e-d3a20881293a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                              SentText  ...                                   RelationMentions\n","1     la corte di appello di campobasso confermava ...  ...  [{'Arg1Text': 'corte di appello', 'Arg2Text': ...\n","2     11 tribunale di pavia, con sentenza 4 , su ri...  ...  [{'Arg1Text': 'tribunale', 'Arg2Text': 'borsan...\n","3     la corte di appello di firenze ha confermato ...  ...  [{'Arg1Text': 'corte di appello', 'Arg2Text': ...\n","4     il tribunale di milano, in riforma della sent...  ...  [{'Arg1Text': 'tribunale', 'Arg2Text': 'herrer...\n","5     la corte di appello di perugia, in parziale r...  ...  [{'Arg1Text': 'corte di appello', 'Arg2Text': ...\n","..                                                 ...  ...                                                ...\n","166   con la sentenza impugnata la corte di appello...  ...  [{'Arg1Text': 'corte di appello', 'Arg2Text': ...\n","167   la corte di appello di ancona, con la sentenz...  ...  [{'Arg1Text': 'tribunale', 'Arg2Text': 'villan...\n","168   francesco mastrogiaconno, attraverso il propr...  ...  [{'Arg1Text': 'difensore', 'Arg2Text': 'france...\n","169   con l ordinanza indicata in epigrafe, emessa ...  ...  [{'Arg1Text': 'tribunale', 'Arg2Text': 'castag...\n","170   con ordinanza in data 23/07/2021- dep. 4/08/2...  ...  [{'Arg1Text': 'tribunale', 'Arg2Text': 'kumbul...\n","\n","[169 rows x 3 columns]"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split"],"metadata":{"id":"RgiSgBWEGKgl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_annotated, dev_test = train_test_split(data_annotated, test_size=0.3)\n","dev_annotated, test_annotated = train_test_split(dev_test, test_size=0.5)"],"metadata":{"id":"sp18qpfW0ehS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","def transform_json(df,filename):\n","    output = []\n","    for i in range(df.shape[0]):\n","        output.append(create_dict(df.iloc[i]))\n","    with open(data_path + f'/{filename}.txt', 'w') as fout:\n","        json.dump(output, fout)"],"metadata":{"id":"JxGZFU_-i6tL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transform_json(data_annotated, 'prova')"],"metadata":{"id":"dzBgb7gymwDH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_json(data_path +'/prova.txt')"],"metadata":{"id":"Fty91D8zm1Pr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.iloc[44]['document']"],"metadata":{"id":"wG4xf8hl9_10","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1641753114298,"user_tz":-60,"elapsed":342,"user":{"displayName":"GIANMARCO PEPI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04653772218915222099"}},"outputId":"7e1b7d57-fe9a-49a9-d5a3-ba7fc3f9e826"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' con la sentenza impugnata la corte d appello di venezia ha disposto la consegna all autoritÃ  giudiziaria tedesca di ioan rosus, in esecuzione di un mandato di arresto europeo processuale emesso in data 12 agosto 2021 dal penale 6 45207 an021presidente: criscuolo annarelatore: d arcangelo fabriziodata udienza: 06/12/2021tribunale di wuppertal per il reato di furto in abitazione asseritamente commesso dal soggetto richiesto in consegna in data 22/12/2021 a velbert. 2. l '"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["distances = []\n","for i in range(df.shape[0]):\n","    for diz in df.iloc[i]['relations']:\n","        m = abs(diz['head'] - diz['child'])\n","        distances.append(m)\n","print(distances)\n","print(max(distances))"],"metadata":{"id":"lZge7YuCnfyF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641753114598,"user_tz":-60,"elapsed":9,"user":{"displayName":"GIANMARCO PEPI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04653772218915222099"}},"outputId":"c7eb2f24-606b-4dd3-a16a-5c9dd6452d60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[21, 17, 20, 10, 26, 68, 7, 7, 11, 14, 14, 15, 10, 17, 21, 10, 22, 15, 23, 22, 6, 13, 18, 22, 26, 7, 6, 11, 21, 18, 17, 28, 17, 20, 23, 20, 42, 19, 22, 9, 20, 28, 13, 17, 2, 25, 6, 23, 8, 11, 14, 14, 25, 25, 15, 40, 19, 2, 23, 27, 2, 27, 17, 22, 6, 6, 39, 20, 6, 18, 23, 9, 19, 8, 7, 23, 25, 18, 70, 60, 50, 9, 7, 14, 9, 2, 8, 11, 7, 16, 14, 2, 7, 28, 16, 16, 15, 16, 5, 5, 8, 2, 19, 23, 33, 32, 30, 12, 6, 6, 32, 16, 12, 8, 20, 22, 18, 19, 22, 15, 11, 9, 30, 33, 28, 31, 34, 37, 4, 12, 31, 18, 11, 5, 27, 27, 11, 9, 9, 39, 32, 9, 12, 23, 11, 14, 17, 20, 23, 26, 22, 11, 25, 14, 18, 22, 7, 12, 60, 50, 67, 33, 36, 39, 42, 21, 22, 35, 19, 2, 4, 35, 39, 43, 9, 12, 22, 9, 6, 6, 6, 19, 24, 7, 20, 19, 31, 18, 18, 13, 25, 13, 6, 25, 8, 26, 6, 6, 12, 9]\n","70\n"]}]},{"cell_type":"code","source":["transform_json(train_annotated, 'relation_training')\n","transform_json(test_annotated, 'relation_test')\n","transform_json(dev_annotated, 'relation_dev')"],"metadata":{"id":"bmNJ27aqlG1E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Convert json files to spacy binary files"],"metadata":{"id":"K4l8Xa9bY7Fg"}},{"cell_type":"code","source":["import json\n","\n","\n","from pathlib import Path\n","\n","from spacy.tokens import Span, DocBin, Doc\n","from spacy.vocab import Vocab\n","from wasabi import Printer\n","from spacy.tokenizer import Tokenizer\n","#from spacy.lang.en import English\n","from spacy.util import compile_infix_regex\n","import re\n","import spacy\n","\n","nlp = spacy.blank(\"it\")\n","# Create a blank Tokenizer with just the English vocab\n","\n","msg = Printer()\n","\n","SYMM_LABELS = [\"Binds\"]\n","MAP_LABELS = {\n","    \"DIFENDE\": \"DIFENDE\",\n","    \"GIUDICA\": \"GIUDICA\"\n","}\n","\n","\n","def main(json_loc: Path, output_file: Path):\n","    \"\"\"Creating the corpus from the Prodigy annotations.\"\"\"\n","    Doc.set_extension(\"rel\", default={},force=True)\n","    vocab = Vocab()\n","\n","    docs = {\"train\": [], \"dev\": [], \"test\": [], \"total\": []}\n","    ids = {\"train\": set(), \"dev\": set(), \"test\": set(), \"total\":set()}\n","    count_all = {\"train\": 0, \"dev\": 0, \"test\": 0,\"total\": 0}\n","    count_pos = {\"train\": 0, \"dev\": 0, \"test\": 0,\"total\": 0}\n","\n","    with open(json_loc, encoding=\"utf8\") as jsonfile:\n","        file = json.load(jsonfile)\n","        i = 0\n","        for example in file:\n","            span_starts = set()\n","            neg = 0\n","            pos = 0\n","                    # Parse the tokens\n","            tokens=nlp(example[\"document\"])    \n","\n","            spaces=[]\n","            spaces = [True if tok.whitespace_ else False for tok in tokens]\n","            words = [t.text for t in tokens]\n","            doc = Doc(nlp.vocab, words=words, spaces=spaces)\n","\n","\n","            # Parse the GGP entities\n","            spans = example[\"tokens\"]\n","            entities = []\n","            span_end_to_start = {}\n","            for span in spans:\n","                entity = doc.char_span(\n","                     span[\"start\"], span[\"end\"], label=span[\"entityLabel\"]\n","                 )\n","                \n","\n","                span_end_to_start[span[\"token_start\"]] = span[\"token_start\"]\n","                #print(span_end_to_start)\n","                entities.append(entity)\n","                span_starts.add(span[\"token_start\"])\n","            #print(entities)\n","            doc.ents = entities\n","            #print(i)\n","            i += 1\n","\n","            # Parse the relations\n","            rels = {}\n","            for x1 in span_starts:\n","                for x2 in span_starts:\n","                    rels[(x1, x2)] = {}\n","                    #print(rels)\n","            relations = example[\"relations\"]\n","            #print(len(relations))\n","            for relation in relations:\n","                # the 'head' and 'child' annotations refer to the end token in the span\n","                # but we want the first token\n","                start = span_end_to_start[relation[\"head\"]]\n","                end = span_end_to_start[relation[\"child\"]]\n","                label = relation[\"relationLabel\"]\n","                #print(rels[(start, end)])\n","                #print(label)\n","                #label = MAP_LABELS[label]\n","                if label not in rels[(start, end)]:\n","                    rels[(start, end)][label] = 1.0\n","                    pos += 1\n","                    #print(pos)\n","                    #print(rels[(start, end)])\n","\n","            # The annotation is complete, so fill in zero's where the data is missing\n","            for x1 in span_starts:\n","                for x2 in span_starts:\n","                    for label in MAP_LABELS.values():\n","                        if label not in rels[(x1, x2)]:\n","                            neg += 1\n","                            rels[(x1, x2)][label] = 0.0\n","\n","                            #print(rels[(x1, x2)])\n","            doc._.rel = rels\n","            #print(doc._.rel)\n","\n","            # only keeping documents with at least 1 positive case\n","            if pos > 0:\n","                    docs[\"total\"].append(doc)\n","                    count_pos[\"total\"] += pos\n","                    count_all[\"total\"] += pos + neg\n","\n","                    \n","                    \n","    #print(len(docs[\"total\"]))\n","    docbin = DocBin(docs=docs[\"total\"], store_user_data=True)\n","    docbin.to_disk(output_file)\n","    msg.info(\n","        f\"{len(docs['total'])} training sentences\"\n","    )\n","    #print(docs)"],"metadata":{"id":"I-k0qYZImEC_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_file = data_path + '/train.spacy'\n","dev_file = data_path + '/dev.spacy'\n","test_file = data_path + '/test.spacy'"],"metadata":{"id":"XD3eULZ6y2ba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["main(data_path +'/relation_test.txt', test_file)"],"metadata":{"id":"BWC0fMnT5UOP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641753140062,"user_tz":-60,"elapsed":1213,"user":{"displayName":"GIANMARCO PEPI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04653772218915222099"}},"outputId":"d59205d6-5bc9-4f44-fefd-73efcd7fc3ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;4mâ„¹ 26 training sentences\u001b[0m\n"]}]},{"cell_type":"code","source":["main(data_path +'/relation_dev.txt', dev_file)"],"metadata":{"id":"A8w0z4Yf5USd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641753144098,"user_tz":-60,"elapsed":12,"user":{"displayName":"GIANMARCO PEPI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04653772218915222099"}},"outputId":"7c40e5f3-c30f-47fb-84e8-e4ad3275993f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;4mâ„¹ 25 training sentences\u001b[0m\n"]}]},{"cell_type":"code","source":["main(data_path +'/relation_training.txt', train_file)"],"metadata":{"id":"GkO0RvE6H82U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641753147963,"user_tz":-60,"elapsed":1363,"user":{"displayName":"GIANMARCO PEPI","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04653772218915222099"}},"outputId":"dcccf682-3fe9-4ed9-a946-38aaf2fb9dae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;4mâ„¹ 118 training sentences\u001b[0m\n"]}]}]}